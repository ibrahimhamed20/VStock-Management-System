#!/bin/bash

# Dual Provider LLM Setup Script
# This script sets up both Ollama and Hugging Face providers

echo "ðŸš€ Setting up Dual Provider LLM System..."

# Check if required packages are installed
echo "ðŸ“¦ Checking dependencies..."
if ! npm list @langchain/community > /dev/null 2>&1; then
    echo "Installing @langchain/community..."
    npm install @langchain/community
fi

# Check if Ollama is running
echo "ðŸ” Checking Ollama status..."
if curl -s http://localhost:11434/api/tags > /dev/null; then
    echo "âœ… Ollama is running"
else
    echo "âŒ Ollama is not running. Starting..."
    docker-compose up -d ollama
    sleep 10
fi

# Install CPU-optimized models for Ollama
echo "ðŸ“¦ Installing CPU-optimized Ollama models..."
ollama pull qwen2.5:0.5b
ollama pull phi3:mini
ollama pull gemma:2b

# Check Hugging Face API key
echo "ðŸ”‘ Checking Hugging Face configuration..."
if [ -z "$HUGGING_FACE_API_KEY" ]; then
    echo "âš ï¸  HUGGING_FACE_API_KEY not set"
    echo "   To use Hugging Face, set your API key:"
    echo "   export HUGGING_FACE_API_KEY=your_key_here"
    echo "   Get your key from: https://huggingface.co/settings/tokens"
else
    echo "âœ… Hugging Face API key is set"
fi

# Create environment file template
echo "ðŸ“ Creating environment template..."
cat > .env.template << EOF
# LLM Provider Configuration
LLM_PROVIDER=ollama  # or 'huggingface'

# Ollama Configuration (Local)
OLLAMA_URL=http://localhost:11434
OLLAMA_CHAT_MODEL=qwen2.5:0.5b
OLLAMA_EMBEDDING_MODEL=nomic-embed-text

# Hugging Face Configuration (Cloud)
HUGGING_FACE_API_KEY=your_api_key_here
HUGGING_FACE_MODEL=microsoft/DialoGPT-medium
EOF

echo ""
echo "ðŸŽ¯ Dual Provider Setup Complete!"
echo ""
echo "ðŸ“Š Available Providers:"
echo "   â€¢ Ollama (Local) - Fast, free, private"
echo "   â€¢ Hugging Face (Cloud) - High quality, managed"
echo ""
echo "ðŸ”§ Configuration:"
echo "   â€¢ Copy .env.template to .env"
echo "   â€¢ Set your Hugging Face API key"
echo "   â€¢ Choose your default provider"
echo ""
echo "ðŸš€ Test Commands:"
echo "   # Test Ollama"
echo "   curl -X POST http://localhost:3000/ai-agent/conversations/test/chat \\"
echo "     -H \"Authorization: Bearer token\" \\"
echo "     -H \"Content-Type: application/json\" \\"
echo "     -d '{\"message\": \"Hello\", \"provider\": \"ollama\"}'"
echo ""
echo "   # Test Hugging Face (if API key is set)"
echo "   curl -X POST http://localhost:3000/ai-agent/conversations/test/chat \\"
echo "     -H \"Authorization: Bearer token\" \\"
echo "     -H \"Content-Type: application/json\" \\"
echo "     -d '{\"message\": \"Hello\", \"provider\": \"huggingface\"}'"
echo ""
echo "   # Switch providers"
echo "   curl -X POST http://localhost:3000/ai-agent/provider/switch \\"
echo "     -H \"Authorization: Bearer token\" \\"
echo "     -H \"Content-Type: application/json\" \\"
echo "     -d '{\"provider\": \"huggingface\"}'"
echo ""
echo "ðŸŽ‰ Your dual provider LLM system is ready!" 